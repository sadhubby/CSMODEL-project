{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 10 - Project Phase 1\n",
    "This notebook is the work and submission of Group 10 of CSMODEl Section S16. The group's members consist of:\n",
    "* David, Peter Jan B.\n",
    "* De Guzman, Evan Mari B.\n",
    "* Manaois, Kyla Nicole G.\n",
    "* Wangkay, Laurize Jeante G.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Description of the Dataset\n",
    "The dataset being used for this study is the Spotify Top-2000s Mega Dataset. This dataset contains the Top 2000 songs in spotify, ranging from the years 1956 to 2019. This dataset has been acquired from Kaggle.com and was produced by the user Sumat Singh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Process\n",
    "In collecting the data, the creator of this dataset used a third party website using this link, http://sortyourmusic.playlistmachinery.com/. This third party website uses the Spotify API to extract the data of a certain song and is then collected. The third party website was created by Paul Lamere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the Dataset\n",
    "The structure of the dataset is quite simple. There exists 1994 observations or rows and there are 15 variables or columns. Each row is an entire set of information of a song, from its title and its artist, to its popularity. Each column represents a certain variable to be discussed further after this section. The only column that has no significance in the dataset is the index column attached with the dataset as to say that the index has no real merit in ranking the song. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables in the Dataset \n",
    "- **`Title`**: Name of the track.\n",
    "- **`Artist`**: Name of the artist.\n",
    "- **`Top Genres`**: Genre that the track applies to.\n",
    "- **`Year`**: Release year of the track.\n",
    "- **`Beats per Minute (BPM)`**: Tempo of the song.\n",
    "- **`Energy`**: Energy of the song. A higher value pertains to the song being more energetic.\n",
    "- **`Danceability`**: Danceability of the song. A higher value pertains to how easier it is to dance to a song.\n",
    "- **`Loudness`**: Loudness of the song. A higher value pertains a louder song. \n",
    "- **`Valence`**: The positivity of a song. A higher value pertains to a more positive mood for the song.\n",
    "- **`Length`**: The duration of the song.\n",
    "- **`Acoustic`**: The acoustic value of the song. A higher value pertains that the song was made less electronically. \n",
    "- **`Speechiness`**: The presence of spoken words in the song. A higher value pertains that the song has more spoken words.\n",
    "- **`Popularity`**: The popularity of a song. A higher value pertains to a more popular song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "For this section of the notebook, our main focus is simply cleaning the dataset. To fufill this purpose, it is a necessity to import the numpy and the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to load the dataset and view the first few rows with the use of `head()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = pd.read_csv(\"Spotify-2000.csv\")\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to view the general dataset information with the use of `info()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the `info()` function, we can see that there are 1994 observations and 15 columns. And within the same function, we get to see that there are exactly 1994 non-null items in every column. To double-check, this code is employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to further check the correctness of the data, the Title and Artists should have capitalized strings. To do so, the group employed the use of a function to return a boolean checking if the first character of a string is capitalized or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_capitalized(s):\n",
    "    return s == s.title()\n",
    "\n",
    "is_title = spotify_df['Title'].apply(is_capitalized)\n",
    "is_artist = spotify_df['Artist'].apply(is_capitalized)\n",
    "\n",
    "capital_check = pd.DataFrame(\n",
    "    {\n",
    "    'Title' : is_title,\n",
    "    'Artist' : is_artist\n",
    "    }\n",
    ")\n",
    "capital_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniqueness of Values\n",
    "\n",
    "Now, there exists another possible problem in regards to the uniqueness of certain values. For example, the title \"Hallelujah\" has 3 different instances. Isolated within the variable 'Title', a method of data cleaning could have been employed. However, considering other variables such as Artist or Top Genre along with BPM, Valence and the such, no method of data cleaning will be employed on such values with the same title and thus are considered unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.loc[(spotify_df['Title'] == 'Hallelujah')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Index Column\n",
    "\n",
    "Here is a point of contention within the group for the use of the dataset within this section. The dataset is, by all means, clean. All Titles and Artists have correct data types and are in one proper format. The only problem that is noticed within this dataset is the use of an artificial number column called 'Index'. \n",
    "\n",
    "Meaning to say, the elements under 'Index' are simply numbers that have no real meaning or information. So as to say, a song having the Index number 1 does not denote it to be the Top 1 song in any possible relation with a variable. Due to this, it was decided upon by the group to have the Index column removed. To justify this decision, as mentioned, it is simply an incrementing artificial number and has no real value. Furthermore, data frames have a built-in identifying index per observation and thus is also redundant. To drop the column, the `drop()` function shall be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = spotify_df.drop(['Index'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectively, there are now only 14 columns or variables of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Top Genres\n",
    "\n",
    "The `Top Genres` column is quite a polarizing one. Consider that there are genres which are more categorically general but the dataset specifies the genre to the most possible specificity. In which case, the pre-processing of this data will require the group to bin and map nearly every possible unique entry to a general genre. \n",
    "\n",
    "First, the group will get the number of unique values within `Top Genres` using the `unique()` and `size` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df['Top Genre'].unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the code above, it returns 149 unique values in the Top Genre. By all metrics, there is too much and no possible relationships or conclusions can be made with this level of specificity. Thus, the group will create a function that checks the string within `Top Genre` and if falls under a specific condition. This condition generalizes all specific genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                  Iris\n",
       "Artist                    The Goo Goo Dolls\n",
       "Top Genre                  alternative rock\n",
       "Year                                   2007\n",
       "Beats Per Minute (BPM)                  156\n",
       "Energy                                   79\n",
       "Danceability                             29\n",
       "Loudness (dB)                            -6\n",
       "Liveness                                  8\n",
       "Valence                                  51\n",
       "Length (Duration)                       290\n",
       "Acousticness                              0\n",
       "Speechiness                               4\n",
       "Popularity                               75\n",
       "General Genre                          rock\n",
       "Name: 36, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generalized_genre(genre):\n",
    "    if 'metal' in genre:\n",
    "        return 'metal'\n",
    "    elif 'pop' in genre:\n",
    "        return 'pop'\n",
    "    elif 'rock' in genre:\n",
    "        return 'rock'\n",
    "    elif 'hip hop' in genre:\n",
    "        return 'hip hop'\n",
    "    elif 'adult' in genre:\n",
    "        return 'adult'\n",
    "    elif 'indie' in genre:\n",
    "        return  'indie'\n",
    "    elif any(sub_genre in genre for sub_genre in ['soul' or 'blues' or 'funk' or 'disco' or 'reggae']):\n",
    "        return 'R&B'\n",
    "    elif 'folk' in genre:\n",
    "        return 'folk'\n",
    "    elif 'british invasion' in genre:\n",
    "        return 'rock'\n",
    "    elif 'country' in genre:\n",
    "        return 'country'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "spotify_df['General Genre'] = spotify_df['Top Genre'].apply(generalized_genre)\n",
    "spotify_df.loc[36]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, The song \"Iris\" by The Goo Goo Dolls is listed as \"alternate rock\". With the function that the group has applied, there now is a related `General Genre` with the generalized value \"rock\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "The nature of this dataset is practically clean, besides the redundant `Index` column. In this case, to make up for the lack of need of data cleaning, the group will instead do feature engineering. In essence, the group will try to create new variables that can be of value for further analysis and study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we can make a categorized mood category that uses the Valence and Energy variables, called the `Affective Mood`. There would be three moods, those being Happy, Calm or Sad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mood_category(row):\n",
    "    if row['Valence'] > 50 and row['Energy'] > 50:\n",
    "        return 'Happy'\n",
    "    elif row['Valence'] > 50 and row['Energy'] <= 50:\n",
    "        return 'Calm'\n",
    "    else:\n",
    "        return 'Sad'\n",
    "\n",
    "spotify_df['Affective Mood'] = spotify_df.apply(mood_category, axis = 1)\n",
    "spotify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature that we can add is the decade of the release of the song. For this, our primary focus is the `Year` variable and making a `Decade` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df['Decade'] = (spotify_df['Year'] // 10) * 10\n",
    "spotify_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
